{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with WANDB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Unpacking data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_score_h.76.0</th>\n",
       "      <th>experiment_score_h.38.0</th>\n",
       "      <th>experiment_score_h.46.0</th>\n",
       "      <th>experiment_score_h.90.0</th>\n",
       "      <th>experiment_score_h.68.0</th>\n",
       "      <th>experiment_score_h.15.0</th>\n",
       "      <th>experiment_score_h.53.0</th>\n",
       "      <th>experiment_score_h.61.0</th>\n",
       "      <th>experiment_score_h.41.0</th>\n",
       "      <th>experiment_score_h.4.0</th>\n",
       "      <th>...</th>\n",
       "      <th>experiment_score_h.52.0</th>\n",
       "      <th>experiment_score_h.56.0</th>\n",
       "      <th>experiment_score_h.29.0</th>\n",
       "      <th>experiment_score_h.48.0</th>\n",
       "      <th>experiment_score_h.21.0</th>\n",
       "      <th>experiment_score_h.67.0</th>\n",
       "      <th>experiment_score_h.39.0</th>\n",
       "      <th>experiment_score_h.20.0</th>\n",
       "      <th>experiment_score_h.16.0</th>\n",
       "      <th>experiment_score_h.27.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.301371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092844</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.412229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.508663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>489 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     experiment_score_h.76.0  experiment_score_h.38.0  \\\n",
       "0                        0.0                  0.00000   \n",
       "1                        0.0                  0.00000   \n",
       "2                        0.0                  0.00000   \n",
       "3                        0.0                  0.09614   \n",
       "4                        0.0                  0.00000   \n",
       "..                       ...                      ...   \n",
       "484                      0.0                  0.00000   \n",
       "485                      0.0                  0.00000   \n",
       "486                      0.0                  0.00000   \n",
       "487                      0.0                  0.00000   \n",
       "488                      0.0                  0.00000   \n",
       "\n",
       "     experiment_score_h.46.0  experiment_score_h.90.0  \\\n",
       "0                   0.000000                      0.0   \n",
       "1                   0.301371                      0.0   \n",
       "2                   0.000000                      0.0   \n",
       "3                   0.000000                      0.0   \n",
       "4                   0.000000                      0.0   \n",
       "..                       ...                      ...   \n",
       "484                 0.000000                      0.0   \n",
       "485                 0.000000                      0.0   \n",
       "486                 0.000000                      0.0   \n",
       "487                 0.000000                      0.0   \n",
       "488                 0.000000                      0.0   \n",
       "\n",
       "     experiment_score_h.68.0  experiment_score_h.15.0  \\\n",
       "0                        0.0                      0.0   \n",
       "1                        0.0                      0.0   \n",
       "2                        0.0                      0.0   \n",
       "3                        0.0                      0.0   \n",
       "4                        0.0                      0.0   \n",
       "..                       ...                      ...   \n",
       "484                      0.0                      0.0   \n",
       "485                      0.0                      0.0   \n",
       "486                      0.0                      0.0   \n",
       "487                      0.0                      0.0   \n",
       "488                      0.0                      0.0   \n",
       "\n",
       "     experiment_score_h.53.0  experiment_score_h.61.0  \\\n",
       "0                        0.0                 0.000000   \n",
       "1                        0.0                 0.000000   \n",
       "2                        0.0                 0.000000   \n",
       "3                        0.0                 0.000000   \n",
       "4                        0.0                 0.000000   \n",
       "..                       ...                      ...   \n",
       "484                      0.0                 0.000000   \n",
       "485                      0.0                 0.000000   \n",
       "486                      0.0                 0.000000   \n",
       "487                      0.0                 0.508663   \n",
       "488                      0.0                 0.000000   \n",
       "\n",
       "     experiment_score_h.41.0  experiment_score_h.4.0  ...  \\\n",
       "0                        0.0                0.079324  ...   \n",
       "1                        0.0                0.000000  ...   \n",
       "2                        0.0                0.000000  ...   \n",
       "3                        0.0                0.000000  ...   \n",
       "4                        0.0                0.000000  ...   \n",
       "..                       ...                     ...  ...   \n",
       "484                      0.0                0.000000  ...   \n",
       "485                      0.0                0.000000  ...   \n",
       "486                      0.0                0.000000  ...   \n",
       "487                      0.0                0.000000  ...   \n",
       "488                      0.0                0.000000  ...   \n",
       "\n",
       "     experiment_score_h.52.0  experiment_score_h.56.0  \\\n",
       "0                        0.0                 0.000000   \n",
       "1                        0.0                 0.000000   \n",
       "2                        0.0                 0.000000   \n",
       "3                        0.0                 0.000000   \n",
       "4                        0.0                 0.000000   \n",
       "..                       ...                      ...   \n",
       "484                      0.0                 0.000000   \n",
       "485                      0.0                 0.000000   \n",
       "486                      0.0                 0.000000   \n",
       "487                      0.0                 0.000000   \n",
       "488                      0.0                 0.120384   \n",
       "\n",
       "     experiment_score_h.29.0  experiment_score_h.48.0  \\\n",
       "0                        0.0                 0.000000   \n",
       "1                        0.0                 0.000000   \n",
       "2                        0.0                 0.000000   \n",
       "3                        0.0                 0.136714   \n",
       "4                        0.0                 0.000000   \n",
       "..                       ...                      ...   \n",
       "484                      0.0                 0.000000   \n",
       "485                      0.0                 0.000000   \n",
       "486                      0.0                 0.004789   \n",
       "487                      0.0                 0.000000   \n",
       "488                      0.0                 0.000000   \n",
       "\n",
       "     experiment_score_h.21.0  experiment_score_h.67.0  \\\n",
       "0                        0.0                      0.0   \n",
       "1                        0.0                      0.0   \n",
       "2                        0.0                      0.0   \n",
       "3                        0.0                      0.0   \n",
       "4                        0.0                      0.0   \n",
       "..                       ...                      ...   \n",
       "484                      0.0                      0.0   \n",
       "485                      0.0                      0.0   \n",
       "486                      0.0                      0.0   \n",
       "487                      0.0                      0.0   \n",
       "488                      0.0                      0.0   \n",
       "\n",
       "     experiment_score_h.39.0  experiment_score_h.20.0  \\\n",
       "0                    0.00000                 0.000000   \n",
       "1                    0.00000                 0.000000   \n",
       "2                    0.00000                 0.000000   \n",
       "3                    0.00000                 0.000000   \n",
       "4                    0.00000                 0.000000   \n",
       "..                       ...                      ...   \n",
       "484                  0.00000                 0.000000   \n",
       "485                  0.00000                 0.412229   \n",
       "486                  0.28312                 0.000000   \n",
       "487                  0.00000                 0.000000   \n",
       "488                  0.00000                 0.000000   \n",
       "\n",
       "     experiment_score_h.16.0  experiment_score_h.27.0  \n",
       "0                   0.000000                  0.00000  \n",
       "1                   0.092844                  0.00000  \n",
       "2                   0.000000                  0.11932  \n",
       "3                   0.000000                  0.00000  \n",
       "4                   0.000000                  0.00000  \n",
       "..                       ...                      ...  \n",
       "484                 0.000000                  0.00000  \n",
       "485                 0.000000                  0.00000  \n",
       "486                 0.000000                  0.00000  \n",
       "487                 0.000000                  0.00000  \n",
       "488                 0.000000                  0.00000  \n",
       "\n",
       "[489 rows x 100 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"DEBUG: Unpacking data\")\n",
    "results_path = \"/home/ia23938/Documents/GitHub/ValueSystemsAggregation/data/wandb_run_data/norm-norm-1.csv\"\n",
    "results = pd.read_csv(results_path)\n",
    "\n",
    "results = results.fillna(0)\n",
    "\n",
    "strategies = ['h.', '1.', '10.', 't.']\n",
    "results_by_strategy = []\n",
    "\n",
    "for strategy in strategies:\n",
    "    results_by_strategy.append(results.filter(like='experiment_score_' + strategy))\n",
    "results_by_strategy[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>...</th>\n",
       "      <th>90.0</th>\n",
       "      <th>91.0</th>\n",
       "      <th>92.0</th>\n",
       "      <th>93.0</th>\n",
       "      <th>94.0</th>\n",
       "      <th>95.0</th>\n",
       "      <th>96.0</th>\n",
       "      <th>97.0</th>\n",
       "      <th>98.0</th>\n",
       "      <th>99.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>489 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0  1.0  2.0  3.0       4.0       5.0  6.0  7.0  8.0  9.0  ...  90.0  \\\n",
       "0    0.0  0.0  0.0  0.0  0.079324  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1    0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "2    0.0  0.0  0.0  0.0  0.000000  0.323137  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "3    0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4    0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "..   ...  ...  ...  ...       ...       ...  ...  ...  ...  ...  ...   ...   \n",
       "484  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "485  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "486  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "487  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "488  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "     91.0  92.0  93.0  94.0      95.0      96.0  97.0  98.0  99.0  \n",
       "0     0.0   0.0   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0  \n",
       "1     0.0   0.0   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0  \n",
       "2     0.0   0.0   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0  \n",
       "3     0.0   0.0   0.0   0.0  0.000000  0.083618   0.0   0.0   0.0  \n",
       "4     0.0   0.0   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0  \n",
       "..    ...   ...   ...   ...       ...       ...   ...   ...   ...  \n",
       "484   0.0   0.0   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0  \n",
       "485   0.0   0.0   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0  \n",
       "486   0.0   0.0   0.0   0.0  0.327243  0.000000   0.0   0.0   0.0  \n",
       "487   0.0   0.0   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0  \n",
       "488   0.0   0.0   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0  \n",
       "\n",
       "[489 rows x 100 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_by_strategy = [df.rename(columns=lambda x: x.replace('experiment_score_'+strategy, '')) for df, strategy in zip(results_by_strategy,strategies)]\n",
    "for i in range(len(results_by_strategy)):\n",
    "    results_by_strategy[i] = results_by_strategy[i].reindex(sorted(results_by_strategy[i].columns, key=lambda x: float(x)), axis=1)\n",
    "\n",
    "results_by_strategy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Calculating cumulative divergence\n",
      "Strategy h.: Agent with highest divergence is 83\n",
      "Strategy 1.: Agent with highest divergence is 83\n",
      "Strategy 10.: Agent with highest divergence is 83\n",
      "Strategy t.: Agent with highest divergence is 83\n",
      "Strategy h.: Average divergence is 7.843018554865573\n",
      "Strategy 1.: Average divergence is 7.986650438835425\n",
      "Strategy 10.: Average divergence is 7.855263684318673\n",
      "Strategy t.: Average divergence is 7.763695624910355\n",
      "Strategy h.: Divergence of agent 83 is 18.060420287888512\n",
      "Strategy 1.: Divergence of agent 83 is 17.84453370498478\n",
      "Strategy 10.: Divergence of agent 83 is 18.074030017199668\n",
      "Strategy t.: Divergence of agent 83 is 18.077569579866235\n",
      "Strategy h.: 99th percentile of the worst off agents' divergence: 13.91688360409502\n",
      "Strategy h.: Agents outside the 99th percentile: [83]\n",
      "Strategy 1.: 99th percentile of the worst off agents' divergence: 13.686209828022173\n",
      "Strategy 1.: Agents outside the 99th percentile: [83]\n",
      "Strategy 10.: 99th percentile of the worst off agents' divergence: 14.431281598402915\n",
      "Strategy 10.: Agents outside the 99th percentile: [83]\n",
      "Strategy t.: 99th percentile of the worst off agents' divergence: 13.974398233807673\n",
      "Strategy t.: Agents outside the 99th percentile: [83]\n"
     ]
    }
   ],
   "source": [
    "# Finding cumulative divergence for each strategy\n",
    "print(\"DEBUG: Calculating cumulative divergence\")\n",
    "cumulative_divergence = []\n",
    "\n",
    "for strategy in results_by_strategy:\n",
    "    divergence_for_agent = []\n",
    "    for column in strategy.columns:\n",
    "        divergence_for_agent.append(strategy[column].sum())\n",
    "    cumulative_divergence.append(divergence_for_agent)\n",
    "\n",
    "# Find the agents with the highest divergence for each strategy\n",
    "highest_divergence_agents = [np.argmax(divergence) for divergence in cumulative_divergence]\n",
    "\n",
    "# Print the agents with the highest divergence for each strategy\n",
    "for i, agent in enumerate(highest_divergence_agents):\n",
    "    print(f\"Strategy {strategies[i]}: Agent with highest divergence is {agent}\")\n",
    "\n",
    "# Calculate and print the average divergence for each strategy\n",
    "average_divergence = [np.mean(divergence) for divergence in cumulative_divergence]\n",
    "for i, avg_div in enumerate(average_divergence):\n",
    "    print(f\"Strategy {strategies[i]}: Average divergence is {avg_div}\")\n",
    "\n",
    "# Print the divergence of the agent with the highest divergence for each strategy\n",
    "for i, agent in enumerate(highest_divergence_agents):\n",
    "    print(f\"Strategy {strategies[i]}: Divergence of agent {agent} is {cumulative_divergence[i][agent]}\")\n",
    "\n",
    "# Finding the 99th percentile of agents\n",
    "for i, strategy in enumerate(results_by_strategy):\n",
    "    worst_off_divergence = cumulative_divergence[i]\n",
    "    percentile_99 = np.percentile(worst_off_divergence, 99)\n",
    "    print(f\"Strategy {strategies[i]}: 99th percentile of the worst off agents' divergence: {percentile_99}\")\n",
    "\n",
    "    agents_outside_99th_percentile = [agent for agent in range(len(worst_off_divergence)) if worst_off_divergence[agent] > percentile_99]\n",
    "    print(f\"Strategy {strategies[i]}: Agents outside the 99th percentile: {agents_outside_99th_percentile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the average number of agents outside of a certain percentile for each strategy for every norm run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy h.: Agents with total divergence more than 2 standard deviations from the mean: [23, 76, 80, 87]\n",
      "Strategy 1.: Agents with total divergence more than 2 standard deviations from the mean: [23, 80, 87]\n",
      "Strategy 10.: Agents with total divergence more than 2 standard deviations from the mean: [23, 68, 76, 80]\n",
      "Strategy t.: Agents with total divergence more than 2 standard deviations from the mean: [23, 80, 87]\n"
     ]
    }
   ],
   "source": [
    "# Repeat the process for all 10 runs\n",
    "strategy_1 = []\n",
    "strategy_10 = []\n",
    "strategy_t = []\n",
    "strategy_hcva = []\n",
    "strategy_results = [strategy_1, strategy_10, strategy_t, strategy_hcva]\n",
    "#for run in range(1, 11):\n",
    "#print(\"DEBUG: Unpacking data\")\n",
    "results_path = \"/home/ia23938/Documents/GitHub/ValueSystemsAggregation/data/wandb_run_data/vibrant-vortex-69.csv\"\n",
    "\n",
    "#results_path = \"/home/ia23938/Documents/GitHub/ValueSystemsAggregation/data/wandb_run_data/norm-util-run-\"+str(run)+\".csv\"\n",
    "results = pd.read_csv(results_path)\n",
    "\n",
    "results = results.fillna(0)\n",
    "\n",
    "strategies = ['h.', '1.', '10.', 't.']\n",
    "\n",
    "results_by_strategy = []\n",
    "\n",
    "for strategy in strategies:\n",
    "    results_by_strategy.append(results.filter(like='experiment_score_' + strategy))\n",
    "results_by_strategy[0]\n",
    "\n",
    "results_by_strategy = [df.rename(columns=lambda x: x.replace('experiment_score_'+strategy, '')) for df, strategy in zip(results_by_strategy,strategies)]\n",
    "for i in range(len(results_by_strategy)):\n",
    "    results_by_strategy[i] = results_by_strategy[i].reindex(sorted(results_by_strategy[i].columns, key=lambda x: float(x)), axis=1)\n",
    "\n",
    "results_by_strategy[0]\n",
    "\n",
    "# Finding cumulative divergence for each strategy\n",
    "#print(\"DEBUG: Calculating cumulative divergence\")\n",
    "cumulative_divergence = []\n",
    "\n",
    "for strategy in results_by_strategy:\n",
    "    divergence_for_agent = []\n",
    "    for column in strategy.columns:\n",
    "        divergence_for_agent.append(strategy[column].sum())\n",
    "    cumulative_divergence.append(divergence_for_agent)\n",
    "\n",
    "# Find the agents with the highest divergence for each strategy\n",
    "highest_divergence_agents = [np.argmax(divergence) for divergence in cumulative_divergence]\n",
    "\n",
    "# Print the agents with the highest divergence for each strategy\n",
    "#for i, agent in enumerate(highest_divergence_agents):\n",
    "#    print(f\"Strategy {strategies[i]}: Agent with highest divergence is {agent}\")\n",
    "\n",
    "# Calculate and print the average divergence for each strategy\n",
    "#average_divergence = [np.mean(divergence) for divergence in cumulative_divergence]\n",
    "#for i, avg_div in enumerate(average_divergence):\n",
    "#    print(f\"Strategy {strategies[i]}: Average divergence is {avg_div}\")\n",
    "\n",
    "# Print the divergence of the agent with the highest divergence for each strategy\n",
    "#for i, agent in enumerate(highest_divergence_agents):\n",
    "#    print(f\"Strategy {strategies[i]}: Divergence of agent {agent} is {cumulative_divergence[i][agent]}\")\n",
    "\n",
    "# Finding the 99th percentile of agents\n",
    "\"\"\"\n",
    "for i, strategy in enumerate(results_by_strategy):\n",
    "    worst_off_divergence = cumulative_divergence[i]\n",
    "    percentile_99 = np.percentile(worst_off_divergence, 98)\n",
    "    #print(f\"Strategy {strategies[i]}: 99th percentile of the worst off agents' divergence: {percentile_99}\")\n",
    "\n",
    "    agents_outside_99th_percentile = [agent for agent in range(len(worst_off_divergence)) if worst_off_divergence[agent] > percentile_99]\n",
    "    #print(f\"Strategy {strategies[i]}: Agents outside the 99th percentile: {agents_outside_99th_percentile}\")\n",
    "    strategy_results[i].append(agents_outside_99th_percentile)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#print(cumulative_divergence)\n",
    "mean_divergence = [np.mean(divergence) for divergence in cumulative_divergence]\n",
    "mean_divergence_of_all = np.mean(mean_divergence)\n",
    "standard_deviation_divergence = [np.std(divergence) for divergence in cumulative_divergence]\n",
    "# standardise this\n",
    "\n",
    "# find the bottom 10, and boxplot it\n",
    "\n",
    "# Finding the statistically significant unsatisfied agents\n",
    "for i, strategy in enumerate(results_by_strategy):\n",
    "    unsatisfied_agents = [agent for agent in range(len(cumulative_divergence[i])) if cumulative_divergence[i][agent] > mean_divergence[i] + 2 * standard_deviation_divergence[i]]\n",
    "    #unsatisfied_agents = [agent for agent in range(len(cumulative_divergence[i])) if cumulative_divergence[i][agent] > mean_divergence_of_all + 2 * standard_deviation_divergence[i]]\n",
    "    print(f\"Strategy {strategies[i]}: Agents with total divergence more than 2 standard deviations from the mean: {unsatisfied_agents}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding whether there is an agent that is consistently the worst off. \n",
    "- For every decision, find the agent that was the worst off, then plot this, when there is a different agent that is the worst off, plot this but in a different colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 80, 80, 80]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(worst_off_agents[\u001b[38;5;241m0\u001b[39m], marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWorst Off Agent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Highlight changes in the worst off agent with a different color\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworst_off_agents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m worst_off_agents[\u001b[38;5;241m0\u001b[39m][i] \u001b[38;5;241m!=\u001b[39m worst_off_agents[\u001b[38;5;241m0\u001b[39m][i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     14\u001b[0m         plt\u001b[38;5;241m.\u001b[39mplot(i, worst_off_agents[i], marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the agent with the minimum satisfaction for each context\n",
    "\n",
    "\n",
    "# Plot the worst off agents\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(worst_off_agents[0], marker='o', linestyle='-', color='b', label='Worst Off Agent')\n",
    "\n",
    "# Highlight changes in the worst off agent with a different color\n",
    "for i in range(1, len(worst_off_agents[0])):\n",
    "    if worst_off_agents[0][i] != worst_off_agents[0][i-1]:\n",
    "        plt.plot(i, worst_off_agents[i], marker='o', color='r')\n",
    "\n",
    "plt.xlabel('Context')\n",
    "plt.ylabel('Agent')\n",
    "plt.title('Worst Off Agent for Each Context')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_size_groups(data: pd.DataFrame):\n",
    "    # This function splits up the dataframe into 3 corresponding to the sizes of 25x4, 10x10, and 4x25 for analysis by group\n",
    "\n",
    "    # Contexts' 0-24 are the first 25x4, contexts' 25-34 are the first 10x10, contexts' 35-38 are the first 4x25. then the context value resets\n",
    "    #   to 0 and this continues\n",
    "    df_list = []\n",
    "    size_groups = [(0, 25), (25, 35), (35, 39)]\n",
    "    for start, end in size_groups:\n",
    "        df_group = data[(data['context'] >= start) & (data['context'] < end)].reset_index(drop=True)\n",
    "        df_list.append(df_group)\n",
    "\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_data(filename: str):\n",
    "    df = pd.read_csv(filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Unpacking data\n"
     ]
    }
   ],
   "source": [
    "print(\"DEBUG: Unpacking data\")\n",
    "plot_savename = \"/home/ia23938/Documents/GitHub/ValueSystemsAggregation/bluepebble_plots/\"\n",
    "results_path = \"/home/ia23938/Documents/GitHub/ValueSystemsAggregation/bluepebble_runs/experiment_results_2024-09-27/\"\n",
    "results_filename = {'egal': \"egal_society/egal_societyegal_society.csv\", 'norm': \"norm_society/norm_societynorm_society.csv\", \"util\": \"util_society/util_societyutil_society.csv\", \"random\": \"rand_society/rand_societyrand_society.csv\"}\n",
    "\n",
    "data = unpack_data(results_path + results_filename[\"util\"])\n",
    "\n",
    "#data = split_into_size_groups(data)\n",
    "\n",
    "#data[0]\n",
    "\n",
    "#for name, filename in results_filename.items():\n",
    "#    data = unpack_data(results_path + filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max/Min over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For every context, find the agent that is the worst off in terms of divergence, and store as a list\n",
    "see if one agent (or a small group of agents in a minority) are consistently the worst off\n",
    "\"\"\"\n",
    "df_dict = {}\n",
    "unique_p_values = data['p_value'].unique()\n",
    "# Split the DataFrame by P_Value\n",
    "for p_value in unique_p_values:\n",
    "    df_dict[f'df_p_{p_value}'] = data[data['p_value'] == p_value].reset_index(drop=True)\n",
    "for key in df_dict.keys():\n",
    "    df_dict[key] = df_dict[key].sort_values(by=['agent', 'context']).reset_index(drop=True)\n",
    "results_dict = {}\n",
    "# Iterate over each DataFrame in df_dict\n",
    "for key, df in df_dict.items():\n",
    "    # Group by 'context'\n",
    "    grouped = df.groupby('context')\n",
    "    max_min_list = []\n",
    "    for name, group in grouped:\n",
    "        max_row = group.loc[group['satisfaction'].idxmax()]\n",
    "        min_row = group.loc[group['satisfaction'].idxmin()]\n",
    "        max_min_list.append({\n",
    "            'context': name,\n",
    "            'agent_max': max_row['agent'],\n",
    "            'satisfaction_max': max_row['satisfaction'],\n",
    "            'agent_min': min_row['agent'],\n",
    "            'satisfaction_min': min_row['satisfaction']\n",
    "        })\n",
    "    results_dict[key] = pd.DataFrame(max_min_list)\n",
    "\n",
    "# Save results_dict to a .csv file\n",
    "for key, df in results_dict.items():\n",
    "    df.to_csv(f\"{key}_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'df_p_0_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf_p_0_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'df_p_0_1'"
     ]
    }
   ],
   "source": [
    "results_dict['df_p_0_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_p_values:  [0 1 2 3]\n",
      "Df keys:  dict_keys(['df_p_0', 'df_p_1', 'df_p_2', 'df_p_3'])\n"
     ]
    }
   ],
   "source": [
    "df_dict = {}\n",
    "unique_p_values = data['p_value'].unique()\n",
    "print(\"unique_p_values: \", unique_p_values)\n",
    "# Split the DataFrame by P_Value\n",
    "for p_value in unique_p_values:\n",
    "    df_dict[f'df_p_{p_value}'] = data[data['p_value'] == p_value].reset_index(drop=True)\n",
    "print(\"Df keys: \", df_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       context  p_value  agent  satisfaction\n",
      "0            0        0   78.0      0.193128\n",
      "1            0        0   69.0      0.123980\n",
      "2            0        0   68.0      0.326464\n",
      "3            0        0   25.0      0.022045\n",
      "4            1        0   41.0      0.162506\n",
      "...        ...      ...    ...           ...\n",
      "32395       38        0   42.0      0.185328\n",
      "32396       38        0   90.0      0.188128\n",
      "32397       38        0   23.0      0.209505\n",
      "32398       38        0   62.0      0.221764\n",
      "32399       38        0   89.0      0.027335\n",
      "\n",
      "[32400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_dict['df_p_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['df_p_0', 'df_p_1', 'df_p_2', 'df_p_3'])\n",
      "      context  satisfaction  p_value\n",
      "0           0      0.665617        0\n",
      "1           1      1.076129        0\n",
      "2           2      1.176029        0\n",
      "3           3      1.294335        0\n",
      "4           4      1.594306        0\n",
      "...       ...           ...      ...\n",
      "4207       34      1.545451        0\n",
      "4208       35      5.131808        0\n",
      "4209       36      5.342436        0\n",
      "4210       37      4.751475        0\n",
      "4211       38      3.872615        0\n",
      "\n",
      "[4212 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "# Iterate over each DataFrame in df_dict\n",
    "for key, df in df_dict.items():\n",
    "    # Group by continuous segments where 'context' is unchanging\n",
    "    df['group'] = (df['context'] != df['context'].shift()).cumsum()\n",
    "    # Sum the 'satisfaction' values for each group\n",
    "    grouped = df.groupby('group').agg({\n",
    "        'context': 'first',\n",
    "        'satisfaction': 'sum'\n",
    "    }).reset_index(drop=True)\n",
    "    \n",
    "    # Add the p_value to the grouped DataFrame\n",
    "    grouped['p_value'] = df['p_value'].iloc[0]\n",
    "    \n",
    "    # Store the result in the dictionary with p_value as the key\n",
    "    results_dict[f'df_p_{grouped[\"p_value\"].iloc[0]}'] = grouped\n",
    "\n",
    "# Print the keys of the results dictionary to verify\n",
    "print(results_dict.keys())\n",
    "print(results_dict['df_p_0'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "value-agg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
