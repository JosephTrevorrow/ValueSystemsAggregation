{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rankings_payoffs.ipynb\n",
    "\n",
    "- Egalitarianism minimises the disadvantage of the worst off agent\n",
    "    - Utilitarianism is the maximisation of total utility\n",
    "\n",
    "- The purpose of rankings here is to remove the extent to which you prefer one solution to another\n",
    "\n",
    "This notebook will\n",
    "- Normalise the the rankings of a utilitarian solution in relation to an egalitarian one, and compare.\n",
    "\n",
    "- Given an agents principles, create rankings based on how much they wish to be influenced by another agents rankings(?)\n",
    "    - A preferred ranking of their preferences considering their ethical principle\n",
    "\n",
    "- Once an agents ranking has been computed, we compare the distance between their rankings, and the rankings of each consensus (Egal, Util, Transition, HCVA) to find closest.\n",
    "\n",
    "#### Full Explanation for clarity\n",
    "Each agent is comprised of a value system, and a principle preference\n",
    "- The value system has, for every value, a preference value of each value over every other value. These are our preferences.\n",
    "    - The value system also has, for every action, an action judgement for every value. The action judgement tells us how much each value in the system would be promoted or demoted if that action is taken.\n",
    "- Additionally, the principle preference tells us the extent to which the agent prefers a principle over another principle. As there are only 2 principles this is a number between 0-1. 0 signfies full support for Utilitarianism, and 1.0 signifies full support for egalitarianism\n",
    "\n",
    "Here the principle preference isnt simply a vote for one thing or another, its just a distance measure. When every agents principle preferences are collated, we optimise on them to find HCVA. We could always use another metric, such as MSE of the principle preferences.\n",
    "\n",
    "To convert these distances to rankings, we need to check each agents principle preference (a number between 0 and 1), convert that preference to an actual principle value (between 1.0 and 10.0), and then rank the 4 options based on their distance from the agents real preferred principle value.\n",
    "- This removes the extent one solution is preferred over the other\n",
    "- This gives an accurate ranking of each agents preference for each solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files chosen for use here are the processed_data from the European Social Study (1 action, 2 values) where the values for each nation have been multipled by a preference factor of 2.5 and an action factor of 5.0 giving a transition point of 1.40 and HCVA point of 2.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed files/libs\n",
    "import pandas as pd\n",
    "\n",
    "agent_data_path = \"/home/ia23938/Documents/GitHub/ValueSystemsAggregation/data/ess_example_data/processed_data_one_action_ess.csv_with_factor_2.5_5.0.csv\"\n",
    "agent_data_df = pd.read_csv(agent_data_path)\n",
    "\n",
    "consensus_data_path_pref = \"/home/ia23938/Documents/GitHub/ValueSystemsAggregation/data/ess_example_data/single_example_results/02-01-2025-actions-a-2.5-p-5.0.csv\"\n",
    "consensus_data_path_act = \"/home/ia23938/Documents/GitHub/ValueSystemsAggregation/data/ess_example_data/single_example_results/02-01-2025-preferences-a-2.5-p-5.0.csv\"\n",
    "temp_pref = pd.read_csv(consensus_data_path_pref)\n",
    "temp_act = pd.read_csv(consensus_data_path_act)\n",
    "consensus_data_df = pd.merge(temp_pref, temp_act, on='p')\n",
    "\n",
    "agent_principle_data_path = \"/home/ia23938/Documents/GitHub/ValueSystemsAggregation/data/ess_example_data/single_example_results/02-01-2025-principles.csv\"\n",
    "agent_principle_data_df = pd.read_csv(agent_principle_data_path)\n",
    "agent_principle_data_df.rename(columns={'rel': 'egal', 'nonrel': 'util'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create rankings of preferences for each consensus\n",
    "\n",
    "consensus_rankings = {\"util\": 1.0, \"egal\": 10.0, \"t\": 1.4, \"hcva\": 2.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>egal</th>\n",
       "      <th>util</th>\n",
       "      <th>normalised_value</th>\n",
       "      <th>principle_value</th>\n",
       "      <th>hcva_rank</th>\n",
       "      <th>t_rank</th>\n",
       "      <th>util_rank</th>\n",
       "      <th>egal_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>0.109795</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BE</td>\n",
       "      <td>834.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>0.480138</td>\n",
       "      <td>5.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>0.099791</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CZ</td>\n",
       "      <td>309.0</td>\n",
       "      <td>1751.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE</td>\n",
       "      <td>440.0</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>0.159884</td>\n",
       "      <td>2.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EE</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ES</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>0.149708</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FI</td>\n",
       "      <td>496.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>0.269859</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FR</td>\n",
       "      <td>216.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>0.110092</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GB</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>0.159737</td>\n",
       "      <td>2.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HU</td>\n",
       "      <td>512.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>0.389650</td>\n",
       "      <td>4.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IE</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0.910194</td>\n",
       "      <td>9.19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IL</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0.600094</td>\n",
       "      <td>6.40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IS</td>\n",
       "      <td>86.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>0.109974</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IT</td>\n",
       "      <td>932.0</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>0.420198</td>\n",
       "      <td>4.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LT</td>\n",
       "      <td>393.0</td>\n",
       "      <td>1316.0</td>\n",
       "      <td>0.229959</td>\n",
       "      <td>3.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NL</td>\n",
       "      <td>475.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>0.300063</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NO</td>\n",
       "      <td>237.0</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>0.159811</td>\n",
       "      <td>2.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PL</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>0.119861</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PT</td>\n",
       "      <td>897.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0.760169</td>\n",
       "      <td>7.84</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RU</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>0.659853</td>\n",
       "      <td>6.94</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SE</td>\n",
       "      <td>187.0</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>0.130314</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SI</td>\n",
       "      <td>923.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0.769808</td>\n",
       "      <td>7.93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country    egal    util  normalised_value  principle_value  hcva_rank  \\\n",
       "0       AT   204.0  1654.0          0.109795             1.99        1.0   \n",
       "1       BE   834.0   903.0          0.480138             5.32        1.0   \n",
       "2       CH   143.0  1290.0          0.099791             1.90        1.0   \n",
       "3       CZ   309.0  1751.0          0.150000             2.35        1.0   \n",
       "4       DE   440.0  2312.0          0.159884             2.44        1.0   \n",
       "5       EE   192.0  1728.0          0.100000             1.90        1.0   \n",
       "6       ES   256.0  1454.0          0.149708             2.35        1.0   \n",
       "7       FI   496.0  1342.0          0.269859             3.43        1.0   \n",
       "8       FR   216.0  1746.0          0.110092             1.99        1.0   \n",
       "9       GB   292.0  1536.0          0.159737             2.44        1.0   \n",
       "10      HU   512.0   802.0          0.389650             4.51        1.0   \n",
       "11      IE  2250.0   222.0          0.910194             9.19        2.0   \n",
       "12      IL  1274.0   849.0          0.600094             6.40        2.0   \n",
       "13      IS    86.0   696.0          0.109974             1.99        1.0   \n",
       "14      IT   932.0  1286.0          0.420198             4.78        1.0   \n",
       "15      LT   393.0  1316.0          0.229959             3.07        1.0   \n",
       "16      NL   475.0  1108.0          0.300063             3.70        1.0   \n",
       "17      NO   237.0  1246.0          0.159811             2.44        1.0   \n",
       "18      PL   172.0  1263.0          0.119861             2.08        1.0   \n",
       "19      PT   897.0   283.0          0.760169             7.84        2.0   \n",
       "20      RU  1259.0   649.0          0.659853             6.94        2.0   \n",
       "21      SE   187.0  1248.0          0.130314             2.17        1.0   \n",
       "22      SI   923.0   276.0          0.769808             7.93        2.0   \n",
       "\n",
       "    t_rank  util_rank  egal_rank  \n",
       "0      2.0        3.0        4.0  \n",
       "1      2.0        3.0        4.0  \n",
       "2      2.0        3.0        4.0  \n",
       "3      2.0        3.0        4.0  \n",
       "4      2.0        3.0        4.0  \n",
       "5      2.0        3.0        4.0  \n",
       "6      2.0        3.0        4.0  \n",
       "7      2.0        3.0        4.0  \n",
       "8      2.0        3.0        4.0  \n",
       "9      2.0        3.0        4.0  \n",
       "10     2.0        3.0        4.0  \n",
       "11     3.0        4.0        1.0  \n",
       "12     3.0        4.0        1.0  \n",
       "13     2.0        3.0        4.0  \n",
       "14     2.0        3.0        4.0  \n",
       "15     2.0        3.0        4.0  \n",
       "16     2.0        3.0        4.0  \n",
       "17     2.0        3.0        4.0  \n",
       "18     2.0        3.0        4.0  \n",
       "19     3.0        4.0        1.0  \n",
       "20     3.0        4.0        1.0  \n",
       "21     2.0        3.0        4.0  \n",
       "22     3.0        4.0        1.0  "
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for row in agent_principle_data_df.iterrows():\n",
    "    index, row_data = row\n",
    "    egal = row_data['egal']\n",
    "    util = row_data['util']\n",
    "    # Normalising means that egal is 0 and util is 1\n",
    "    normalised_value = egal / (egal + util)\n",
    "    agent_principle_data_df.at[index, 'normalised_value'] = normalised_value\n",
    "\n",
    "# Now each row is normalised, we convert the normalised value into the principle value for each agent, between 1.0 and 10.0\n",
    "for row in agent_principle_data_df.iterrows():\n",
    "    index, row_data = row\n",
    "    normalised_value = row_data['normalised_value']\n",
    "    principle_value = normalised_value * 9 + 1\n",
    "    agent_principle_data_df.at[index, 'principle_value'] = round(principle_value, 2)\n",
    "\n",
    "# Now calculate the ranking for of consensus rankings for each principle we are interested in\n",
    "for row in agent_principle_data_df.iterrows():\n",
    "    index, row_data = row\n",
    "    temp_distances = {}\n",
    "    for principle, value in consensus_rankings.items():\n",
    "        agent_principle = row_data['principle_value']\n",
    "        temp_distances[principle] = abs(agent_principle - value)\n",
    "    temp_distances = {key: value for key, value in sorted(temp_distances.items(), key=lambda item: item[1])}\n",
    "    # Place in dataframe for agent\n",
    "    for i, (principle, distance) in enumerate(temp_distances.items()):\n",
    "        agent_principle_data_df.at[index, principle + \"_rank\"] = i + 1\n",
    "\n",
    "agent_principle_data_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results in LaTeX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " & 1.000000 & 2.000000 & 3.000000 & 4.000000 \\\\\n",
      "\\midrule\n",
      "hcva_rank & 18 & 5 & 0 & 0 \\\\\n",
      "t_rank & 0 & 18 & 5 & 0 \\\\\n",
      "util_rank & 0 & 0 & 18 & 5 \\\\\n",
      "egal_rank & 5 & 0 & 0 & 18 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the frequency of each strategy at each rank\n",
    "rank_frequencies = agent_principle_data_df[['hcva_rank', 't_rank', 'util_rank', 'egal_rank']].apply(pd.Series.value_counts).fillna(0).astype(int)\n",
    "\n",
    "# Create a LaTeX table\n",
    "latex_rank_frequencies = rank_frequencies.T.to_latex()\n",
    "\n",
    "print(latex_rank_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " & hcva_rank & t_rank & util_rank & egal_rank \\\\\n",
      "\\midrule\n",
      "Sum of Ranks & 28.000000 & 51.000000 & 74.000000 & 77.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sum up the ranks for each principle\n",
    "rank_sums = agent_principle_data_df[['hcva_rank', 't_rank', 'util_rank', 'egal_rank']].sum()\n",
    "\n",
    "# Create a LaTeX table\n",
    "latex_table = rank_sums.to_frame(name='Sum of Ranks').T.to_latex()\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider the principle value system, rather than the distance away from the principle value itself\n",
    "\n",
    "Repeat the same code again, formatting dataframes for comaprision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_data_df = agent_data_df[['country','Rel-Nonrel','Nonrel-Rel', 'a_div_rel', 'a_div_nonrel']]\n",
    "agent_principle_data_df = agent_principle_data_df[['country','principle_value']]\n",
    "agent_data_df = pd.merge(agent_data_df, agent_principle_data_df, on='country')\n",
    "agent_data_df.rename(columns={'principle_value': 'p', 'a_div_rel' : 'Rel_div_p', 'a_div_nonrel': 'Nonrel_div_p'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_data_path_pref = \"/home/ia23938/Documents/GitHub/ValueSystemsAggregation/data/ess_example_data/single_example_results/02-01-2025-actions-a-2.5-p-5.0.csv\"\n",
    "consensus_data_path_act = \"/home/ia23938/Documents/GitHub/ValueSystemsAggregation/data/ess_example_data/single_example_results/02-01-2025-preferences-a-2.5-p-5.0.csv\"\n",
    "temp_pref = pd.read_csv(consensus_data_path_pref)\n",
    "temp_act = pd.read_csv(consensus_data_path_act)\n",
    "consensus_data_df = pd.merge(temp_pref, temp_act, on='p')\n",
    "consensus_data_df = consensus_data_df[['p','Rel_div_p', 'Nonrel_div_p', 'Rel-Nonrel', 'Nonrel-Rel']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalising the values for comparison\n",
    "\n",
    "The values can't just be the distance between each one, as the scale between each value is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country  Rel-Nonrel  Nonrel-Rel  Rel_div_p  Nonrel_div_p     p  p_normalised\n",
      "0      AT    0.622644    0.377356   0.619418      0.780976  1.99      0.012346\n",
      "1      BE    0.597369    0.402631   0.340311      0.364098  5.32      0.469136\n",
      "2      CH    0.222415    0.777585   0.877010      1.000000  1.90      0.000000\n",
      "3      CZ    0.760694    0.239306   0.553437      0.572488  2.35      0.061728\n",
      "4      DE    0.382623    0.617377   0.505274      0.670251  2.44      0.074074\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>Rel_div_p</th>\n",
       "      <th>Nonrel_div_p</th>\n",
       "      <th>Rel-Nonrel</th>\n",
       "      <th>Nonrel-Rel</th>\n",
       "      <th>p_normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027241</td>\n",
       "      <td>0.972759</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.212419</td>\n",
       "      <td>0.512429</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.996897</td>\n",
       "      <td>0.043956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.1</td>\n",
       "      <td>0.019615</td>\n",
       "      <td>0.261700</td>\n",
       "      <td>0.265724</td>\n",
       "      <td>0.734276</td>\n",
       "      <td>0.120879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.583467</td>\n",
       "      <td>0.005097</td>\n",
       "      <td>0.996726</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.989011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       p  Rel_div_p  Nonrel_div_p  Rel-Nonrel  Nonrel-Rel  p_normalised\n",
       "0    1.0   1.000000      1.000000    0.027241    0.972759      0.000000\n",
       "4    1.4   0.212419      0.512429    0.003103    0.996897      0.043956\n",
       "11   2.1   0.019615      0.261700    0.265724    0.734276      0.120879\n",
       "90  10.0   0.583467      0.005097    0.996726    0.003274      0.989011"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalise all data between 0-1\n",
    "consensus_data_df = consensus_data_df.astype(float)\n",
    "unnormalised_consensus_data_df = consensus_data_df.copy()\n",
    "for row in consensus_data_df.iterrows():\n",
    "    for column in consensus_data_df.columns:\n",
    "        min_val = consensus_data_df[column].min()\n",
    "        max_val = consensus_data_df[column].max()\n",
    "        if column == 'p':\n",
    "            consensus_data_df['p_normalised'] = consensus_data_df['p']\n",
    "            column = 'p_normalised'\n",
    "        consensus_data_df[column] = (consensus_data_df[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "# Filter consensus_data_df to keep only rows with p values of 1.0 1.4, 2.1, 10.0\n",
    "relevant_p_values = [1.0, 1.4, 2.1, 10.0]\n",
    "tolerance = 1e-5\n",
    "consensus_data_df = consensus_data_df[consensus_data_df['p'].apply(lambda x: any(abs(x - val) < tolerance for val in relevant_p_values))]\n",
    "\n",
    "\n",
    "# Now the same for agents, but work from the unnormalised consensus data\n",
    "for row in agent_data_df.iterrows():\n",
    "    for column in agent_data_df.columns:\n",
    "        if column == 'country' or column == 'p_normalised':\n",
    "            continue\n",
    "        min_val = agent_data_df[column].min()\n",
    "        max_val = agent_data_df[column].max()\n",
    "        if column == 'p':\n",
    "            agent_data_df['p_normalised'] = agent_data_df['p']\n",
    "            column = 'p_normalised'\n",
    "        agent_data_df[column] = (agent_data_df[column] - min_val) / (max_val - min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'principle_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/value-agg/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'principle_value'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[523], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m consensus_data_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      6\u001b[0m     index, consensus_data \u001b[38;5;241m=\u001b[39m row\n\u001b[0;32m----> 8\u001b[0m     agent_principle \u001b[38;5;241m=\u001b[39m \u001b[43mrow_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprinciple_value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m     temp_distances[principle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(agent_principle \u001b[38;5;241m-\u001b[39m value)\n\u001b[1;32m     10\u001b[0m temp_distances \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(temp_distances\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m item: item[\u001b[38;5;241m1\u001b[39m])}\n",
      "File \u001b[0;32m~/miniconda3/envs/value-agg/lib/python3.11/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/miniconda3/envs/value-agg/lib/python3.11/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/envs/value-agg/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'principle_value'"
     ]
    }
   ],
   "source": [
    "# Now calculate the ranking for of consensus rankings for each principle we are interested in\n",
    "for row in agent_data_df.iterrows():\n",
    "    index, row_data = row\n",
    "    temp_distances = {}\n",
    "    for row in consensus_data_df.iterrows():\n",
    "        index, consensus_data = row\n",
    "        for data in row.columns:\n",
    "            temp_distances[consensus_data['p']] = abs(row_data['p'] - consensus_data['p'])\n",
    "        \n",
    "            temp_distances[principle] = abs(agent_principle - value)\n",
    "    temp_distances = {key: value for key, value in sorted(temp_distances.items(), key=lambda item: item[1])}\n",
    "\n",
    "\n",
    "    # Place in dataframe for agent\n",
    "    for i, (principle, distance) in enumerate(temp_distances.items()):\n",
    "        agent_data_df.at[index, principle + \"_rank\"] = i + 1\n",
    "\n",
    "comparison_data = ['Rel_div_p', 'Nonrel_div_p', 'Rel-Nonrel', 'Nonrel-Rel', 'p']\n",
    "for row in agent_data_df.iterrows():\n",
    "    index, row_data = row\n",
    "    temp_distances = {}\n",
    "    for row in consensus_data_df.iterrows():\n",
    "        index, consensus_data = row\n",
    "        for data in comparision_data:\n",
    "            temp_distances[consensus_data['p']] = abs(row_data['p'] - consensus_data['p'])\n",
    "\n",
    "\n",
    "agent_principle_data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "value-agg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
